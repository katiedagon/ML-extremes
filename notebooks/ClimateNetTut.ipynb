{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#runs pre trained model and stores in output in a nc file. \n",
    "# Basics\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "#os.environ[\"PROJ_LIB\"] = \"/global/homes/a/anayak/.conda/envs/pytorch-gpu/share/proj\"\n",
    "os.environ[\"PROJ_LIB\"] = \"/glade/p/cgd/amp/jet/collections/anaconda3/envs/lbltorch/share/proj\"\n",
    "\n",
    "sys.path.append('/glade/u/home/jet/ClimateNet/ncar')\n",
    "\n",
    "# Netcdf4\n",
    "import datetime\n",
    "from netCDF4 import Dataset\n",
    "\n",
    "#architecture\n",
    "from architecture import CGNet_wrap as cg\n",
    "from architecture import deeplab_xception\n",
    "\n",
    "# Torch\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from dataset import cam_dataset_nc as nc_dataset\n",
    "#from utils import visualizeUtil,utils\n",
    "from utils import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda is not available: using cpu\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# CUDA for PyTorch\n",
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda:0\" if use_cuda else \"cpu\")\n",
    "torch.backends.cudnn.benchmark = True\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "   print(\"cuda is available: using gpu\")\n",
    "   map_location=lambda storage, loc: storage.cuda()\n",
    "else:\n",
    "   print(\"cuda is not available: using cpu\")\n",
    "   map_location='cpu'\n",
    "#device = torch.device(\"cpu\")\n",
    "#map_location='cpu'\n",
    "#use_cuda = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "arch = \"cgnet\" # \"cgnet\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "have droput layer\n",
      "Let's use 0 cpu\n"
     ]
    }
   ],
   "source": [
    "#data and output paths\n",
    "data_dir = \"/glade/scratch/jet/ClimateNet/Climate_data/\" \n",
    "if arch == \"deep\" :\n",
    "    model_path = \"/glade/u/home/jet/ClimateNet/ncar/architecture/ClimateNet_model.pth\"\n",
    "    output_dir = \"/glade/scratch/jet/ClimateNet/output.deep/\"\n",
    "    net = deeplab_xception.DeepLabv3_plus(nInputChannels=4, n_classes=3, os=16)\n",
    "else:\n",
    "    model_path = \"/glade/u/home/jet/ClimateNet/ncar/architecture/CGNet_wrap.pth\" #change to your desired pth file \n",
    "    output_dir = \"/glade/scratch/jet/ClimateNet/output.cgnet/\"\n",
    "    net = cg.CGNet(classes=3, channels=4, M=3, N=21, dropout_flag=True)\n",
    "\n",
    "    #if torch.cuda.device_count() > 1:\n",
    "print(\"Let's use\", torch.cuda.device_count(), device)\n",
    "# dim = 0 [30, xxx] -> [10, ...], [10, ...], [10, ...] on 3 GPUs\n",
    "net = torch.nn.parallel.DataParallel(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataParallel(\n",
       "  (module): CGNet(\n",
       "    (level1_0): ConvBNPReLU(\n",
       "      (padding): Wrap()\n",
       "      (conv): Conv2d(4, 32, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "      (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act): PReLU(num_parameters=32)\n",
       "    )\n",
       "    (level1_1): ConvBNPReLU(\n",
       "      (padding): Wrap()\n",
       "      (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act): PReLU(num_parameters=32)\n",
       "    )\n",
       "    (level1_2): ConvBNPReLU(\n",
       "      (padding): Wrap()\n",
       "      (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act): PReLU(num_parameters=32)\n",
       "    )\n",
       "    (sample1): InputInjection(\n",
       "      (pool): ModuleList(\n",
       "        (0): Wrap()\n",
       "        (1): AvgPool2d(kernel_size=3, stride=2, padding=0)\n",
       "      )\n",
       "    )\n",
       "    (sample2): InputInjection(\n",
       "      (pool): ModuleList(\n",
       "        (0): Wrap()\n",
       "        (1): AvgPool2d(kernel_size=3, stride=2, padding=0)\n",
       "        (2): Wrap()\n",
       "        (3): AvgPool2d(kernel_size=3, stride=2, padding=0)\n",
       "      )\n",
       "    )\n",
       "    (b1): BNPReLU(\n",
       "      (bn): BatchNorm2d(36, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act): PReLU(num_parameters=36)\n",
       "    )\n",
       "    (level2_0): ContextGuidedBlock_Down(\n",
       "      (conv1x1): ConvBNPReLU(\n",
       "        (padding): Wrap()\n",
       "        (conv): Conv2d(36, 64, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act): PReLU(num_parameters=64)\n",
       "      )\n",
       "      (F_loc): ChannelWiseConv(\n",
       "        (padding): Wrap()\n",
       "        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), groups=64, bias=False)\n",
       "      )\n",
       "      (F_sur): ChannelWiseDilatedConv(\n",
       "        (padding): Wrap()\n",
       "        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), dilation=(2, 2), groups=64, bias=False)\n",
       "      )\n",
       "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act): PReLU(num_parameters=128)\n",
       "      (reduce): Conv(\n",
       "        (padding): Wrap()\n",
       "        (conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (F_glo): FGlo(\n",
       "        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "        (fc): Sequential(\n",
       "          (0): Linear(in_features=64, out_features=8, bias=True)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Linear(in_features=8, out_features=64, bias=True)\n",
       "          (3): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (level2): ModuleList(\n",
       "      (0): ContextGuidedBlock(\n",
       "        (conv1x1): ConvBNPReLU(\n",
       "          (padding): Wrap()\n",
       "          (conv): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act): PReLU(num_parameters=32)\n",
       "        )\n",
       "        (F_loc): ChannelWiseConv(\n",
       "          (padding): Wrap()\n",
       "          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), groups=32, bias=False)\n",
       "        )\n",
       "        (F_sur): ChannelWiseDilatedConv(\n",
       "          (padding): Wrap()\n",
       "          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), dilation=(2, 2), groups=32, bias=False)\n",
       "        )\n",
       "        (bn_prelu): BNPReLU(\n",
       "          (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act): PReLU(num_parameters=64)\n",
       "        )\n",
       "        (F_glo): FGlo(\n",
       "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc): Sequential(\n",
       "            (0): Linear(in_features=64, out_features=8, bias=True)\n",
       "            (1): ReLU(inplace=True)\n",
       "            (2): Linear(in_features=8, out_features=64, bias=True)\n",
       "            (3): Sigmoid()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1): ContextGuidedBlock(\n",
       "        (conv1x1): ConvBNPReLU(\n",
       "          (padding): Wrap()\n",
       "          (conv): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act): PReLU(num_parameters=32)\n",
       "        )\n",
       "        (F_loc): ChannelWiseConv(\n",
       "          (padding): Wrap()\n",
       "          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), groups=32, bias=False)\n",
       "        )\n",
       "        (F_sur): ChannelWiseDilatedConv(\n",
       "          (padding): Wrap()\n",
       "          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), dilation=(2, 2), groups=32, bias=False)\n",
       "        )\n",
       "        (bn_prelu): BNPReLU(\n",
       "          (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act): PReLU(num_parameters=64)\n",
       "        )\n",
       "        (F_glo): FGlo(\n",
       "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc): Sequential(\n",
       "            (0): Linear(in_features=64, out_features=8, bias=True)\n",
       "            (1): ReLU(inplace=True)\n",
       "            (2): Linear(in_features=8, out_features=64, bias=True)\n",
       "            (3): Sigmoid()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (bn_prelu_2): BNPReLU(\n",
       "      (bn): BatchNorm2d(132, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act): PReLU(num_parameters=132)\n",
       "    )\n",
       "    (level3_0): ContextGuidedBlock_Down(\n",
       "      (conv1x1): ConvBNPReLU(\n",
       "        (padding): Wrap()\n",
       "        (conv): Conv2d(132, 128, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act): PReLU(num_parameters=128)\n",
       "      )\n",
       "      (F_loc): ChannelWiseConv(\n",
       "        (padding): Wrap()\n",
       "        (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), groups=128, bias=False)\n",
       "      )\n",
       "      (F_sur): ChannelWiseDilatedConv(\n",
       "        (padding): Wrap()\n",
       "        (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), dilation=(4, 4), groups=128, bias=False)\n",
       "      )\n",
       "      (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act): PReLU(num_parameters=256)\n",
       "      (reduce): Conv(\n",
       "        (padding): Wrap()\n",
       "        (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (F_glo): FGlo(\n",
       "        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "        (fc): Sequential(\n",
       "          (0): Linear(in_features=128, out_features=8, bias=True)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Linear(in_features=8, out_features=128, bias=True)\n",
       "          (3): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (level3): ModuleList(\n",
       "      (0): ContextGuidedBlock(\n",
       "        (conv1x1): ConvBNPReLU(\n",
       "          (padding): Wrap()\n",
       "          (conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act): PReLU(num_parameters=64)\n",
       "        )\n",
       "        (F_loc): ChannelWiseConv(\n",
       "          (padding): Wrap()\n",
       "          (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), groups=64, bias=False)\n",
       "        )\n",
       "        (F_sur): ChannelWiseDilatedConv(\n",
       "          (padding): Wrap()\n",
       "          (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), dilation=(4, 4), groups=64, bias=False)\n",
       "        )\n",
       "        (bn_prelu): BNPReLU(\n",
       "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act): PReLU(num_parameters=128)\n",
       "        )\n",
       "        (F_glo): FGlo(\n",
       "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc): Sequential(\n",
       "            (0): Linear(in_features=128, out_features=8, bias=True)\n",
       "            (1): ReLU(inplace=True)\n",
       "            (2): Linear(in_features=8, out_features=128, bias=True)\n",
       "            (3): Sigmoid()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1): ContextGuidedBlock(\n",
       "        (conv1x1): ConvBNPReLU(\n",
       "          (padding): Wrap()\n",
       "          (conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act): PReLU(num_parameters=64)\n",
       "        )\n",
       "        (F_loc): ChannelWiseConv(\n",
       "          (padding): Wrap()\n",
       "          (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), groups=64, bias=False)\n",
       "        )\n",
       "        (F_sur): ChannelWiseDilatedConv(\n",
       "          (padding): Wrap()\n",
       "          (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), dilation=(4, 4), groups=64, bias=False)\n",
       "        )\n",
       "        (bn_prelu): BNPReLU(\n",
       "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act): PReLU(num_parameters=128)\n",
       "        )\n",
       "        (F_glo): FGlo(\n",
       "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc): Sequential(\n",
       "            (0): Linear(in_features=128, out_features=8, bias=True)\n",
       "            (1): ReLU(inplace=True)\n",
       "            (2): Linear(in_features=8, out_features=128, bias=True)\n",
       "            (3): Sigmoid()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (2): ContextGuidedBlock(\n",
       "        (conv1x1): ConvBNPReLU(\n",
       "          (padding): Wrap()\n",
       "          (conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act): PReLU(num_parameters=64)\n",
       "        )\n",
       "        (F_loc): ChannelWiseConv(\n",
       "          (padding): Wrap()\n",
       "          (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), groups=64, bias=False)\n",
       "        )\n",
       "        (F_sur): ChannelWiseDilatedConv(\n",
       "          (padding): Wrap()\n",
       "          (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), dilation=(4, 4), groups=64, bias=False)\n",
       "        )\n",
       "        (bn_prelu): BNPReLU(\n",
       "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act): PReLU(num_parameters=128)\n",
       "        )\n",
       "        (F_glo): FGlo(\n",
       "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc): Sequential(\n",
       "            (0): Linear(in_features=128, out_features=8, bias=True)\n",
       "            (1): ReLU(inplace=True)\n",
       "            (2): Linear(in_features=8, out_features=128, bias=True)\n",
       "            (3): Sigmoid()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (3): ContextGuidedBlock(\n",
       "        (conv1x1): ConvBNPReLU(\n",
       "          (padding): Wrap()\n",
       "          (conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act): PReLU(num_parameters=64)\n",
       "        )\n",
       "        (F_loc): ChannelWiseConv(\n",
       "          (padding): Wrap()\n",
       "          (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), groups=64, bias=False)\n",
       "        )\n",
       "        (F_sur): ChannelWiseDilatedConv(\n",
       "          (padding): Wrap()\n",
       "          (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), dilation=(4, 4), groups=64, bias=False)\n",
       "        )\n",
       "        (bn_prelu): BNPReLU(\n",
       "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act): PReLU(num_parameters=128)\n",
       "        )\n",
       "        (F_glo): FGlo(\n",
       "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc): Sequential(\n",
       "            (0): Linear(in_features=128, out_features=8, bias=True)\n",
       "            (1): ReLU(inplace=True)\n",
       "            (2): Linear(in_features=8, out_features=128, bias=True)\n",
       "            (3): Sigmoid()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (4): ContextGuidedBlock(\n",
       "        (conv1x1): ConvBNPReLU(\n",
       "          (padding): Wrap()\n",
       "          (conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act): PReLU(num_parameters=64)\n",
       "        )\n",
       "        (F_loc): ChannelWiseConv(\n",
       "          (padding): Wrap()\n",
       "          (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), groups=64, bias=False)\n",
       "        )\n",
       "        (F_sur): ChannelWiseDilatedConv(\n",
       "          (padding): Wrap()\n",
       "          (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), dilation=(4, 4), groups=64, bias=False)\n",
       "        )\n",
       "        (bn_prelu): BNPReLU(\n",
       "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act): PReLU(num_parameters=128)\n",
       "        )\n",
       "        (F_glo): FGlo(\n",
       "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc): Sequential(\n",
       "            (0): Linear(in_features=128, out_features=8, bias=True)\n",
       "            (1): ReLU(inplace=True)\n",
       "            (2): Linear(in_features=8, out_features=128, bias=True)\n",
       "            (3): Sigmoid()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (5): ContextGuidedBlock(\n",
       "        (conv1x1): ConvBNPReLU(\n",
       "          (padding): Wrap()\n",
       "          (conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act): PReLU(num_parameters=64)\n",
       "        )\n",
       "        (F_loc): ChannelWiseConv(\n",
       "          (padding): Wrap()\n",
       "          (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), groups=64, bias=False)\n",
       "        )\n",
       "        (F_sur): ChannelWiseDilatedConv(\n",
       "          (padding): Wrap()\n",
       "          (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), dilation=(4, 4), groups=64, bias=False)\n",
       "        )\n",
       "        (bn_prelu): BNPReLU(\n",
       "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act): PReLU(num_parameters=128)\n",
       "        )\n",
       "        (F_glo): FGlo(\n",
       "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc): Sequential(\n",
       "            (0): Linear(in_features=128, out_features=8, bias=True)\n",
       "            (1): ReLU(inplace=True)\n",
       "            (2): Linear(in_features=8, out_features=128, bias=True)\n",
       "            (3): Sigmoid()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (6): ContextGuidedBlock(\n",
       "        (conv1x1): ConvBNPReLU(\n",
       "          (padding): Wrap()\n",
       "          (conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act): PReLU(num_parameters=64)\n",
       "        )\n",
       "        (F_loc): ChannelWiseConv(\n",
       "          (padding): Wrap()\n",
       "          (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), groups=64, bias=False)\n",
       "        )\n",
       "        (F_sur): ChannelWiseDilatedConv(\n",
       "          (padding): Wrap()\n",
       "          (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), dilation=(4, 4), groups=64, bias=False)\n",
       "        )\n",
       "        (bn_prelu): BNPReLU(\n",
       "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act): PReLU(num_parameters=128)\n",
       "        )\n",
       "        (F_glo): FGlo(\n",
       "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc): Sequential(\n",
       "            (0): Linear(in_features=128, out_features=8, bias=True)\n",
       "            (1): ReLU(inplace=True)\n",
       "            (2): Linear(in_features=8, out_features=128, bias=True)\n",
       "            (3): Sigmoid()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (7): ContextGuidedBlock(\n",
       "        (conv1x1): ConvBNPReLU(\n",
       "          (padding): Wrap()\n",
       "          (conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act): PReLU(num_parameters=64)\n",
       "        )\n",
       "        (F_loc): ChannelWiseConv(\n",
       "          (padding): Wrap()\n",
       "          (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), groups=64, bias=False)\n",
       "        )\n",
       "        (F_sur): ChannelWiseDilatedConv(\n",
       "          (padding): Wrap()\n",
       "          (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), dilation=(4, 4), groups=64, bias=False)\n",
       "        )\n",
       "        (bn_prelu): BNPReLU(\n",
       "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act): PReLU(num_parameters=128)\n",
       "        )\n",
       "        (F_glo): FGlo(\n",
       "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc): Sequential(\n",
       "            (0): Linear(in_features=128, out_features=8, bias=True)\n",
       "            (1): ReLU(inplace=True)\n",
       "            (2): Linear(in_features=8, out_features=128, bias=True)\n",
       "            (3): Sigmoid()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (8): ContextGuidedBlock(\n",
       "        (conv1x1): ConvBNPReLU(\n",
       "          (padding): Wrap()\n",
       "          (conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act): PReLU(num_parameters=64)\n",
       "        )\n",
       "        (F_loc): ChannelWiseConv(\n",
       "          (padding): Wrap()\n",
       "          (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), groups=64, bias=False)\n",
       "        )\n",
       "        (F_sur): ChannelWiseDilatedConv(\n",
       "          (padding): Wrap()\n",
       "          (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), dilation=(4, 4), groups=64, bias=False)\n",
       "        )\n",
       "        (bn_prelu): BNPReLU(\n",
       "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act): PReLU(num_parameters=128)\n",
       "        )\n",
       "        (F_glo): FGlo(\n",
       "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc): Sequential(\n",
       "            (0): Linear(in_features=128, out_features=8, bias=True)\n",
       "            (1): ReLU(inplace=True)\n",
       "            (2): Linear(in_features=8, out_features=128, bias=True)\n",
       "            (3): Sigmoid()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (9): ContextGuidedBlock(\n",
       "        (conv1x1): ConvBNPReLU(\n",
       "          (padding): Wrap()\n",
       "          (conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act): PReLU(num_parameters=64)\n",
       "        )\n",
       "        (F_loc): ChannelWiseConv(\n",
       "          (padding): Wrap()\n",
       "          (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), groups=64, bias=False)\n",
       "        )\n",
       "        (F_sur): ChannelWiseDilatedConv(\n",
       "          (padding): Wrap()\n",
       "          (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), dilation=(4, 4), groups=64, bias=False)\n",
       "        )\n",
       "        (bn_prelu): BNPReLU(\n",
       "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act): PReLU(num_parameters=128)\n",
       "        )\n",
       "        (F_glo): FGlo(\n",
       "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc): Sequential(\n",
       "            (0): Linear(in_features=128, out_features=8, bias=True)\n",
       "            (1): ReLU(inplace=True)\n",
       "            (2): Linear(in_features=8, out_features=128, bias=True)\n",
       "            (3): Sigmoid()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (10): ContextGuidedBlock(\n",
       "        (conv1x1): ConvBNPReLU(\n",
       "          (padding): Wrap()\n",
       "          (conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act): PReLU(num_parameters=64)\n",
       "        )\n",
       "        (F_loc): ChannelWiseConv(\n",
       "          (padding): Wrap()\n",
       "          (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), groups=64, bias=False)\n",
       "        )\n",
       "        (F_sur): ChannelWiseDilatedConv(\n",
       "          (padding): Wrap()\n",
       "          (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), dilation=(4, 4), groups=64, bias=False)\n",
       "        )\n",
       "        (bn_prelu): BNPReLU(\n",
       "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act): PReLU(num_parameters=128)\n",
       "        )\n",
       "        (F_glo): FGlo(\n",
       "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc): Sequential(\n",
       "            (0): Linear(in_features=128, out_features=8, bias=True)\n",
       "            (1): ReLU(inplace=True)\n",
       "            (2): Linear(in_features=8, out_features=128, bias=True)\n",
       "            (3): Sigmoid()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (11): ContextGuidedBlock(\n",
       "        (conv1x1): ConvBNPReLU(\n",
       "          (padding): Wrap()\n",
       "          (conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act): PReLU(num_parameters=64)\n",
       "        )\n",
       "        (F_loc): ChannelWiseConv(\n",
       "          (padding): Wrap()\n",
       "          (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), groups=64, bias=False)\n",
       "        )\n",
       "        (F_sur): ChannelWiseDilatedConv(\n",
       "          (padding): Wrap()\n",
       "          (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), dilation=(4, 4), groups=64, bias=False)\n",
       "        )\n",
       "        (bn_prelu): BNPReLU(\n",
       "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act): PReLU(num_parameters=128)\n",
       "        )\n",
       "        (F_glo): FGlo(\n",
       "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc): Sequential(\n",
       "            (0): Linear(in_features=128, out_features=8, bias=True)\n",
       "            (1): ReLU(inplace=True)\n",
       "            (2): Linear(in_features=8, out_features=128, bias=True)\n",
       "            (3): Sigmoid()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (12): ContextGuidedBlock(\n",
       "        (conv1x1): ConvBNPReLU(\n",
       "          (padding): Wrap()\n",
       "          (conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act): PReLU(num_parameters=64)\n",
       "        )\n",
       "        (F_loc): ChannelWiseConv(\n",
       "          (padding): Wrap()\n",
       "          (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), groups=64, bias=False)\n",
       "        )\n",
       "        (F_sur): ChannelWiseDilatedConv(\n",
       "          (padding): Wrap()\n",
       "          (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), dilation=(4, 4), groups=64, bias=False)\n",
       "        )\n",
       "        (bn_prelu): BNPReLU(\n",
       "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act): PReLU(num_parameters=128)\n",
       "        )\n",
       "        (F_glo): FGlo(\n",
       "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc): Sequential(\n",
       "            (0): Linear(in_features=128, out_features=8, bias=True)\n",
       "            (1): ReLU(inplace=True)\n",
       "            (2): Linear(in_features=8, out_features=128, bias=True)\n",
       "            (3): Sigmoid()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (13): ContextGuidedBlock(\n",
       "        (conv1x1): ConvBNPReLU(\n",
       "          (padding): Wrap()\n",
       "          (conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act): PReLU(num_parameters=64)\n",
       "        )\n",
       "        (F_loc): ChannelWiseConv(\n",
       "          (padding): Wrap()\n",
       "          (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), groups=64, bias=False)\n",
       "        )\n",
       "        (F_sur): ChannelWiseDilatedConv(\n",
       "          (padding): Wrap()\n",
       "          (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), dilation=(4, 4), groups=64, bias=False)\n",
       "        )\n",
       "        (bn_prelu): BNPReLU(\n",
       "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act): PReLU(num_parameters=128)\n",
       "        )\n",
       "        (F_glo): FGlo(\n",
       "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc): Sequential(\n",
       "            (0): Linear(in_features=128, out_features=8, bias=True)\n",
       "            (1): ReLU(inplace=True)\n",
       "            (2): Linear(in_features=8, out_features=128, bias=True)\n",
       "            (3): Sigmoid()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (14): ContextGuidedBlock(\n",
       "        (conv1x1): ConvBNPReLU(\n",
       "          (padding): Wrap()\n",
       "          (conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act): PReLU(num_parameters=64)\n",
       "        )\n",
       "        (F_loc): ChannelWiseConv(\n",
       "          (padding): Wrap()\n",
       "          (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), groups=64, bias=False)\n",
       "        )\n",
       "        (F_sur): ChannelWiseDilatedConv(\n",
       "          (padding): Wrap()\n",
       "          (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), dilation=(4, 4), groups=64, bias=False)\n",
       "        )\n",
       "        (bn_prelu): BNPReLU(\n",
       "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act): PReLU(num_parameters=128)\n",
       "        )\n",
       "        (F_glo): FGlo(\n",
       "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc): Sequential(\n",
       "            (0): Linear(in_features=128, out_features=8, bias=True)\n",
       "            (1): ReLU(inplace=True)\n",
       "            (2): Linear(in_features=8, out_features=128, bias=True)\n",
       "            (3): Sigmoid()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (15): ContextGuidedBlock(\n",
       "        (conv1x1): ConvBNPReLU(\n",
       "          (padding): Wrap()\n",
       "          (conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act): PReLU(num_parameters=64)\n",
       "        )\n",
       "        (F_loc): ChannelWiseConv(\n",
       "          (padding): Wrap()\n",
       "          (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), groups=64, bias=False)\n",
       "        )\n",
       "        (F_sur): ChannelWiseDilatedConv(\n",
       "          (padding): Wrap()\n",
       "          (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), dilation=(4, 4), groups=64, bias=False)\n",
       "        )\n",
       "        (bn_prelu): BNPReLU(\n",
       "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act): PReLU(num_parameters=128)\n",
       "        )\n",
       "        (F_glo): FGlo(\n",
       "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc): Sequential(\n",
       "            (0): Linear(in_features=128, out_features=8, bias=True)\n",
       "            (1): ReLU(inplace=True)\n",
       "            (2): Linear(in_features=8, out_features=128, bias=True)\n",
       "            (3): Sigmoid()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (16): ContextGuidedBlock(\n",
       "        (conv1x1): ConvBNPReLU(\n",
       "          (padding): Wrap()\n",
       "          (conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act): PReLU(num_parameters=64)\n",
       "        )\n",
       "        (F_loc): ChannelWiseConv(\n",
       "          (padding): Wrap()\n",
       "          (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), groups=64, bias=False)\n",
       "        )\n",
       "        (F_sur): ChannelWiseDilatedConv(\n",
       "          (padding): Wrap()\n",
       "          (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), dilation=(4, 4), groups=64, bias=False)\n",
       "        )\n",
       "        (bn_prelu): BNPReLU(\n",
       "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act): PReLU(num_parameters=128)\n",
       "        )\n",
       "        (F_glo): FGlo(\n",
       "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc): Sequential(\n",
       "            (0): Linear(in_features=128, out_features=8, bias=True)\n",
       "            (1): ReLU(inplace=True)\n",
       "            (2): Linear(in_features=8, out_features=128, bias=True)\n",
       "            (3): Sigmoid()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (17): ContextGuidedBlock(\n",
       "        (conv1x1): ConvBNPReLU(\n",
       "          (padding): Wrap()\n",
       "          (conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act): PReLU(num_parameters=64)\n",
       "        )\n",
       "        (F_loc): ChannelWiseConv(\n",
       "          (padding): Wrap()\n",
       "          (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), groups=64, bias=False)\n",
       "        )\n",
       "        (F_sur): ChannelWiseDilatedConv(\n",
       "          (padding): Wrap()\n",
       "          (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), dilation=(4, 4), groups=64, bias=False)\n",
       "        )\n",
       "        (bn_prelu): BNPReLU(\n",
       "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act): PReLU(num_parameters=128)\n",
       "        )\n",
       "        (F_glo): FGlo(\n",
       "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc): Sequential(\n",
       "            (0): Linear(in_features=128, out_features=8, bias=True)\n",
       "            (1): ReLU(inplace=True)\n",
       "            (2): Linear(in_features=8, out_features=128, bias=True)\n",
       "            (3): Sigmoid()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (18): ContextGuidedBlock(\n",
       "        (conv1x1): ConvBNPReLU(\n",
       "          (padding): Wrap()\n",
       "          (conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act): PReLU(num_parameters=64)\n",
       "        )\n",
       "        (F_loc): ChannelWiseConv(\n",
       "          (padding): Wrap()\n",
       "          (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), groups=64, bias=False)\n",
       "        )\n",
       "        (F_sur): ChannelWiseDilatedConv(\n",
       "          (padding): Wrap()\n",
       "          (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), dilation=(4, 4), groups=64, bias=False)\n",
       "        )\n",
       "        (bn_prelu): BNPReLU(\n",
       "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act): PReLU(num_parameters=128)\n",
       "        )\n",
       "        (F_glo): FGlo(\n",
       "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc): Sequential(\n",
       "            (0): Linear(in_features=128, out_features=8, bias=True)\n",
       "            (1): ReLU(inplace=True)\n",
       "            (2): Linear(in_features=8, out_features=128, bias=True)\n",
       "            (3): Sigmoid()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (19): ContextGuidedBlock(\n",
       "        (conv1x1): ConvBNPReLU(\n",
       "          (padding): Wrap()\n",
       "          (conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act): PReLU(num_parameters=64)\n",
       "        )\n",
       "        (F_loc): ChannelWiseConv(\n",
       "          (padding): Wrap()\n",
       "          (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), groups=64, bias=False)\n",
       "        )\n",
       "        (F_sur): ChannelWiseDilatedConv(\n",
       "          (padding): Wrap()\n",
       "          (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), dilation=(4, 4), groups=64, bias=False)\n",
       "        )\n",
       "        (bn_prelu): BNPReLU(\n",
       "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act): PReLU(num_parameters=128)\n",
       "        )\n",
       "        (F_glo): FGlo(\n",
       "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc): Sequential(\n",
       "            (0): Linear(in_features=128, out_features=8, bias=True)\n",
       "            (1): ReLU(inplace=True)\n",
       "            (2): Linear(in_features=8, out_features=128, bias=True)\n",
       "            (3): Sigmoid()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (bn_prelu_3): BNPReLU(\n",
       "      (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act): PReLU(num_parameters=256)\n",
       "    )\n",
       "    (classifier): Sequential(\n",
       "      (0): Dropout2d(p=0.1, inplace=False)\n",
       "      (1): Conv(\n",
       "        (padding): Wrap()\n",
       "        (conv): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "checkpoint = torch.load(model_path, map_location=map_location)\n",
    "#checkpoint = torch.load(model_path,map_location=device) #gpu or cpu\n",
    "#print(checkpoint.keys())\n",
    "#print(checkpoint['net_state_dict'])\n",
    "#checkpoint = torch.load(model_path,map_location='cpu') #cpu\n",
    "net.load_state_dict(checkpoint['net_state_dict'])\n",
    "net.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataParallel(\n",
       "  (module): CGNet(\n",
       "    (level1_0): ConvBNPReLU(\n",
       "      (padding): Wrap()\n",
       "      (conv): Conv2d(4, 32, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "      (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act): PReLU(num_parameters=32)\n",
       "    )\n",
       "    (level1_1): ConvBNPReLU(\n",
       "      (padding): Wrap()\n",
       "      (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act): PReLU(num_parameters=32)\n",
       "    )\n",
       "    (level1_2): ConvBNPReLU(\n",
       "      (padding): Wrap()\n",
       "      (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act): PReLU(num_parameters=32)\n",
       "    )\n",
       "    (sample1): InputInjection(\n",
       "      (pool): ModuleList(\n",
       "        (0): Wrap()\n",
       "        (1): AvgPool2d(kernel_size=3, stride=2, padding=0)\n",
       "      )\n",
       "    )\n",
       "    (sample2): InputInjection(\n",
       "      (pool): ModuleList(\n",
       "        (0): Wrap()\n",
       "        (1): AvgPool2d(kernel_size=3, stride=2, padding=0)\n",
       "        (2): Wrap()\n",
       "        (3): AvgPool2d(kernel_size=3, stride=2, padding=0)\n",
       "      )\n",
       "    )\n",
       "    (b1): BNPReLU(\n",
       "      (bn): BatchNorm2d(36, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act): PReLU(num_parameters=36)\n",
       "    )\n",
       "    (level2_0): ContextGuidedBlock_Down(\n",
       "      (conv1x1): ConvBNPReLU(\n",
       "        (padding): Wrap()\n",
       "        (conv): Conv2d(36, 64, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act): PReLU(num_parameters=64)\n",
       "      )\n",
       "      (F_loc): ChannelWiseConv(\n",
       "        (padding): Wrap()\n",
       "        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), groups=64, bias=False)\n",
       "      )\n",
       "      (F_sur): ChannelWiseDilatedConv(\n",
       "        (padding): Wrap()\n",
       "        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), dilation=(2, 2), groups=64, bias=False)\n",
       "      )\n",
       "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act): PReLU(num_parameters=128)\n",
       "      (reduce): Conv(\n",
       "        (padding): Wrap()\n",
       "        (conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (F_glo): FGlo(\n",
       "        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "        (fc): Sequential(\n",
       "          (0): Linear(in_features=64, out_features=8, bias=True)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Linear(in_features=8, out_features=64, bias=True)\n",
       "          (3): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (level2): ModuleList(\n",
       "      (0): ContextGuidedBlock(\n",
       "        (conv1x1): ConvBNPReLU(\n",
       "          (padding): Wrap()\n",
       "          (conv): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act): PReLU(num_parameters=32)\n",
       "        )\n",
       "        (F_loc): ChannelWiseConv(\n",
       "          (padding): Wrap()\n",
       "          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), groups=32, bias=False)\n",
       "        )\n",
       "        (F_sur): ChannelWiseDilatedConv(\n",
       "          (padding): Wrap()\n",
       "          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), dilation=(2, 2), groups=32, bias=False)\n",
       "        )\n",
       "        (bn_prelu): BNPReLU(\n",
       "          (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act): PReLU(num_parameters=64)\n",
       "        )\n",
       "        (F_glo): FGlo(\n",
       "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc): Sequential(\n",
       "            (0): Linear(in_features=64, out_features=8, bias=True)\n",
       "            (1): ReLU(inplace=True)\n",
       "            (2): Linear(in_features=8, out_features=64, bias=True)\n",
       "            (3): Sigmoid()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1): ContextGuidedBlock(\n",
       "        (conv1x1): ConvBNPReLU(\n",
       "          (padding): Wrap()\n",
       "          (conv): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act): PReLU(num_parameters=32)\n",
       "        )\n",
       "        (F_loc): ChannelWiseConv(\n",
       "          (padding): Wrap()\n",
       "          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), groups=32, bias=False)\n",
       "        )\n",
       "        (F_sur): ChannelWiseDilatedConv(\n",
       "          (padding): Wrap()\n",
       "          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), dilation=(2, 2), groups=32, bias=False)\n",
       "        )\n",
       "        (bn_prelu): BNPReLU(\n",
       "          (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act): PReLU(num_parameters=64)\n",
       "        )\n",
       "        (F_glo): FGlo(\n",
       "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc): Sequential(\n",
       "            (0): Linear(in_features=64, out_features=8, bias=True)\n",
       "            (1): ReLU(inplace=True)\n",
       "            (2): Linear(in_features=8, out_features=64, bias=True)\n",
       "            (3): Sigmoid()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (bn_prelu_2): BNPReLU(\n",
       "      (bn): BatchNorm2d(132, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act): PReLU(num_parameters=132)\n",
       "    )\n",
       "    (level3_0): ContextGuidedBlock_Down(\n",
       "      (conv1x1): ConvBNPReLU(\n",
       "        (padding): Wrap()\n",
       "        (conv): Conv2d(132, 128, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act): PReLU(num_parameters=128)\n",
       "      )\n",
       "      (F_loc): ChannelWiseConv(\n",
       "        (padding): Wrap()\n",
       "        (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), groups=128, bias=False)\n",
       "      )\n",
       "      (F_sur): ChannelWiseDilatedConv(\n",
       "        (padding): Wrap()\n",
       "        (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), dilation=(4, 4), groups=128, bias=False)\n",
       "      )\n",
       "      (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act): PReLU(num_parameters=256)\n",
       "      (reduce): Conv(\n",
       "        (padding): Wrap()\n",
       "        (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (F_glo): FGlo(\n",
       "        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "        (fc): Sequential(\n",
       "          (0): Linear(in_features=128, out_features=8, bias=True)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Linear(in_features=8, out_features=128, bias=True)\n",
       "          (3): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (level3): ModuleList(\n",
       "      (0): ContextGuidedBlock(\n",
       "        (conv1x1): ConvBNPReLU(\n",
       "          (padding): Wrap()\n",
       "          (conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act): PReLU(num_parameters=64)\n",
       "        )\n",
       "        (F_loc): ChannelWiseConv(\n",
       "          (padding): Wrap()\n",
       "          (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), groups=64, bias=False)\n",
       "        )\n",
       "        (F_sur): ChannelWiseDilatedConv(\n",
       "          (padding): Wrap()\n",
       "          (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), dilation=(4, 4), groups=64, bias=False)\n",
       "        )\n",
       "        (bn_prelu): BNPReLU(\n",
       "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act): PReLU(num_parameters=128)\n",
       "        )\n",
       "        (F_glo): FGlo(\n",
       "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc): Sequential(\n",
       "            (0): Linear(in_features=128, out_features=8, bias=True)\n",
       "            (1): ReLU(inplace=True)\n",
       "            (2): Linear(in_features=8, out_features=128, bias=True)\n",
       "            (3): Sigmoid()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1): ContextGuidedBlock(\n",
       "        (conv1x1): ConvBNPReLU(\n",
       "          (padding): Wrap()\n",
       "          (conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act): PReLU(num_parameters=64)\n",
       "        )\n",
       "        (F_loc): ChannelWiseConv(\n",
       "          (padding): Wrap()\n",
       "          (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), groups=64, bias=False)\n",
       "        )\n",
       "        (F_sur): ChannelWiseDilatedConv(\n",
       "          (padding): Wrap()\n",
       "          (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), dilation=(4, 4), groups=64, bias=False)\n",
       "        )\n",
       "        (bn_prelu): BNPReLU(\n",
       "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act): PReLU(num_parameters=128)\n",
       "        )\n",
       "        (F_glo): FGlo(\n",
       "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc): Sequential(\n",
       "            (0): Linear(in_features=128, out_features=8, bias=True)\n",
       "            (1): ReLU(inplace=True)\n",
       "            (2): Linear(in_features=8, out_features=128, bias=True)\n",
       "            (3): Sigmoid()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (2): ContextGuidedBlock(\n",
       "        (conv1x1): ConvBNPReLU(\n",
       "          (padding): Wrap()\n",
       "          (conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act): PReLU(num_parameters=64)\n",
       "        )\n",
       "        (F_loc): ChannelWiseConv(\n",
       "          (padding): Wrap()\n",
       "          (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), groups=64, bias=False)\n",
       "        )\n",
       "        (F_sur): ChannelWiseDilatedConv(\n",
       "          (padding): Wrap()\n",
       "          (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), dilation=(4, 4), groups=64, bias=False)\n",
       "        )\n",
       "        (bn_prelu): BNPReLU(\n",
       "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act): PReLU(num_parameters=128)\n",
       "        )\n",
       "        (F_glo): FGlo(\n",
       "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc): Sequential(\n",
       "            (0): Linear(in_features=128, out_features=8, bias=True)\n",
       "            (1): ReLU(inplace=True)\n",
       "            (2): Linear(in_features=8, out_features=128, bias=True)\n",
       "            (3): Sigmoid()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (3): ContextGuidedBlock(\n",
       "        (conv1x1): ConvBNPReLU(\n",
       "          (padding): Wrap()\n",
       "          (conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act): PReLU(num_parameters=64)\n",
       "        )\n",
       "        (F_loc): ChannelWiseConv(\n",
       "          (padding): Wrap()\n",
       "          (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), groups=64, bias=False)\n",
       "        )\n",
       "        (F_sur): ChannelWiseDilatedConv(\n",
       "          (padding): Wrap()\n",
       "          (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), dilation=(4, 4), groups=64, bias=False)\n",
       "        )\n",
       "        (bn_prelu): BNPReLU(\n",
       "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act): PReLU(num_parameters=128)\n",
       "        )\n",
       "        (F_glo): FGlo(\n",
       "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc): Sequential(\n",
       "            (0): Linear(in_features=128, out_features=8, bias=True)\n",
       "            (1): ReLU(inplace=True)\n",
       "            (2): Linear(in_features=8, out_features=128, bias=True)\n",
       "            (3): Sigmoid()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (4): ContextGuidedBlock(\n",
       "        (conv1x1): ConvBNPReLU(\n",
       "          (padding): Wrap()\n",
       "          (conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act): PReLU(num_parameters=64)\n",
       "        )\n",
       "        (F_loc): ChannelWiseConv(\n",
       "          (padding): Wrap()\n",
       "          (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), groups=64, bias=False)\n",
       "        )\n",
       "        (F_sur): ChannelWiseDilatedConv(\n",
       "          (padding): Wrap()\n",
       "          (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), dilation=(4, 4), groups=64, bias=False)\n",
       "        )\n",
       "        (bn_prelu): BNPReLU(\n",
       "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act): PReLU(num_parameters=128)\n",
       "        )\n",
       "        (F_glo): FGlo(\n",
       "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc): Sequential(\n",
       "            (0): Linear(in_features=128, out_features=8, bias=True)\n",
       "            (1): ReLU(inplace=True)\n",
       "            (2): Linear(in_features=8, out_features=128, bias=True)\n",
       "            (3): Sigmoid()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (5): ContextGuidedBlock(\n",
       "        (conv1x1): ConvBNPReLU(\n",
       "          (padding): Wrap()\n",
       "          (conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act): PReLU(num_parameters=64)\n",
       "        )\n",
       "        (F_loc): ChannelWiseConv(\n",
       "          (padding): Wrap()\n",
       "          (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), groups=64, bias=False)\n",
       "        )\n",
       "        (F_sur): ChannelWiseDilatedConv(\n",
       "          (padding): Wrap()\n",
       "          (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), dilation=(4, 4), groups=64, bias=False)\n",
       "        )\n",
       "        (bn_prelu): BNPReLU(\n",
       "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act): PReLU(num_parameters=128)\n",
       "        )\n",
       "        (F_glo): FGlo(\n",
       "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc): Sequential(\n",
       "            (0): Linear(in_features=128, out_features=8, bias=True)\n",
       "            (1): ReLU(inplace=True)\n",
       "            (2): Linear(in_features=8, out_features=128, bias=True)\n",
       "            (3): Sigmoid()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (6): ContextGuidedBlock(\n",
       "        (conv1x1): ConvBNPReLU(\n",
       "          (padding): Wrap()\n",
       "          (conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act): PReLU(num_parameters=64)\n",
       "        )\n",
       "        (F_loc): ChannelWiseConv(\n",
       "          (padding): Wrap()\n",
       "          (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), groups=64, bias=False)\n",
       "        )\n",
       "        (F_sur): ChannelWiseDilatedConv(\n",
       "          (padding): Wrap()\n",
       "          (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), dilation=(4, 4), groups=64, bias=False)\n",
       "        )\n",
       "        (bn_prelu): BNPReLU(\n",
       "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act): PReLU(num_parameters=128)\n",
       "        )\n",
       "        (F_glo): FGlo(\n",
       "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc): Sequential(\n",
       "            (0): Linear(in_features=128, out_features=8, bias=True)\n",
       "            (1): ReLU(inplace=True)\n",
       "            (2): Linear(in_features=8, out_features=128, bias=True)\n",
       "            (3): Sigmoid()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (7): ContextGuidedBlock(\n",
       "        (conv1x1): ConvBNPReLU(\n",
       "          (padding): Wrap()\n",
       "          (conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act): PReLU(num_parameters=64)\n",
       "        )\n",
       "        (F_loc): ChannelWiseConv(\n",
       "          (padding): Wrap()\n",
       "          (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), groups=64, bias=False)\n",
       "        )\n",
       "        (F_sur): ChannelWiseDilatedConv(\n",
       "          (padding): Wrap()\n",
       "          (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), dilation=(4, 4), groups=64, bias=False)\n",
       "        )\n",
       "        (bn_prelu): BNPReLU(\n",
       "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act): PReLU(num_parameters=128)\n",
       "        )\n",
       "        (F_glo): FGlo(\n",
       "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc): Sequential(\n",
       "            (0): Linear(in_features=128, out_features=8, bias=True)\n",
       "            (1): ReLU(inplace=True)\n",
       "            (2): Linear(in_features=8, out_features=128, bias=True)\n",
       "            (3): Sigmoid()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (8): ContextGuidedBlock(\n",
       "        (conv1x1): ConvBNPReLU(\n",
       "          (padding): Wrap()\n",
       "          (conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act): PReLU(num_parameters=64)\n",
       "        )\n",
       "        (F_loc): ChannelWiseConv(\n",
       "          (padding): Wrap()\n",
       "          (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), groups=64, bias=False)\n",
       "        )\n",
       "        (F_sur): ChannelWiseDilatedConv(\n",
       "          (padding): Wrap()\n",
       "          (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), dilation=(4, 4), groups=64, bias=False)\n",
       "        )\n",
       "        (bn_prelu): BNPReLU(\n",
       "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act): PReLU(num_parameters=128)\n",
       "        )\n",
       "        (F_glo): FGlo(\n",
       "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc): Sequential(\n",
       "            (0): Linear(in_features=128, out_features=8, bias=True)\n",
       "            (1): ReLU(inplace=True)\n",
       "            (2): Linear(in_features=8, out_features=128, bias=True)\n",
       "            (3): Sigmoid()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (9): ContextGuidedBlock(\n",
       "        (conv1x1): ConvBNPReLU(\n",
       "          (padding): Wrap()\n",
       "          (conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act): PReLU(num_parameters=64)\n",
       "        )\n",
       "        (F_loc): ChannelWiseConv(\n",
       "          (padding): Wrap()\n",
       "          (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), groups=64, bias=False)\n",
       "        )\n",
       "        (F_sur): ChannelWiseDilatedConv(\n",
       "          (padding): Wrap()\n",
       "          (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), dilation=(4, 4), groups=64, bias=False)\n",
       "        )\n",
       "        (bn_prelu): BNPReLU(\n",
       "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act): PReLU(num_parameters=128)\n",
       "        )\n",
       "        (F_glo): FGlo(\n",
       "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc): Sequential(\n",
       "            (0): Linear(in_features=128, out_features=8, bias=True)\n",
       "            (1): ReLU(inplace=True)\n",
       "            (2): Linear(in_features=8, out_features=128, bias=True)\n",
       "            (3): Sigmoid()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (10): ContextGuidedBlock(\n",
       "        (conv1x1): ConvBNPReLU(\n",
       "          (padding): Wrap()\n",
       "          (conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act): PReLU(num_parameters=64)\n",
       "        )\n",
       "        (F_loc): ChannelWiseConv(\n",
       "          (padding): Wrap()\n",
       "          (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), groups=64, bias=False)\n",
       "        )\n",
       "        (F_sur): ChannelWiseDilatedConv(\n",
       "          (padding): Wrap()\n",
       "          (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), dilation=(4, 4), groups=64, bias=False)\n",
       "        )\n",
       "        (bn_prelu): BNPReLU(\n",
       "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act): PReLU(num_parameters=128)\n",
       "        )\n",
       "        (F_glo): FGlo(\n",
       "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc): Sequential(\n",
       "            (0): Linear(in_features=128, out_features=8, bias=True)\n",
       "            (1): ReLU(inplace=True)\n",
       "            (2): Linear(in_features=8, out_features=128, bias=True)\n",
       "            (3): Sigmoid()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (11): ContextGuidedBlock(\n",
       "        (conv1x1): ConvBNPReLU(\n",
       "          (padding): Wrap()\n",
       "          (conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act): PReLU(num_parameters=64)\n",
       "        )\n",
       "        (F_loc): ChannelWiseConv(\n",
       "          (padding): Wrap()\n",
       "          (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), groups=64, bias=False)\n",
       "        )\n",
       "        (F_sur): ChannelWiseDilatedConv(\n",
       "          (padding): Wrap()\n",
       "          (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), dilation=(4, 4), groups=64, bias=False)\n",
       "        )\n",
       "        (bn_prelu): BNPReLU(\n",
       "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act): PReLU(num_parameters=128)\n",
       "        )\n",
       "        (F_glo): FGlo(\n",
       "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc): Sequential(\n",
       "            (0): Linear(in_features=128, out_features=8, bias=True)\n",
       "            (1): ReLU(inplace=True)\n",
       "            (2): Linear(in_features=8, out_features=128, bias=True)\n",
       "            (3): Sigmoid()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (12): ContextGuidedBlock(\n",
       "        (conv1x1): ConvBNPReLU(\n",
       "          (padding): Wrap()\n",
       "          (conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act): PReLU(num_parameters=64)\n",
       "        )\n",
       "        (F_loc): ChannelWiseConv(\n",
       "          (padding): Wrap()\n",
       "          (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), groups=64, bias=False)\n",
       "        )\n",
       "        (F_sur): ChannelWiseDilatedConv(\n",
       "          (padding): Wrap()\n",
       "          (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), dilation=(4, 4), groups=64, bias=False)\n",
       "        )\n",
       "        (bn_prelu): BNPReLU(\n",
       "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act): PReLU(num_parameters=128)\n",
       "        )\n",
       "        (F_glo): FGlo(\n",
       "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc): Sequential(\n",
       "            (0): Linear(in_features=128, out_features=8, bias=True)\n",
       "            (1): ReLU(inplace=True)\n",
       "            (2): Linear(in_features=8, out_features=128, bias=True)\n",
       "            (3): Sigmoid()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (13): ContextGuidedBlock(\n",
       "        (conv1x1): ConvBNPReLU(\n",
       "          (padding): Wrap()\n",
       "          (conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act): PReLU(num_parameters=64)\n",
       "        )\n",
       "        (F_loc): ChannelWiseConv(\n",
       "          (padding): Wrap()\n",
       "          (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), groups=64, bias=False)\n",
       "        )\n",
       "        (F_sur): ChannelWiseDilatedConv(\n",
       "          (padding): Wrap()\n",
       "          (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), dilation=(4, 4), groups=64, bias=False)\n",
       "        )\n",
       "        (bn_prelu): BNPReLU(\n",
       "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act): PReLU(num_parameters=128)\n",
       "        )\n",
       "        (F_glo): FGlo(\n",
       "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc): Sequential(\n",
       "            (0): Linear(in_features=128, out_features=8, bias=True)\n",
       "            (1): ReLU(inplace=True)\n",
       "            (2): Linear(in_features=8, out_features=128, bias=True)\n",
       "            (3): Sigmoid()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (14): ContextGuidedBlock(\n",
       "        (conv1x1): ConvBNPReLU(\n",
       "          (padding): Wrap()\n",
       "          (conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act): PReLU(num_parameters=64)\n",
       "        )\n",
       "        (F_loc): ChannelWiseConv(\n",
       "          (padding): Wrap()\n",
       "          (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), groups=64, bias=False)\n",
       "        )\n",
       "        (F_sur): ChannelWiseDilatedConv(\n",
       "          (padding): Wrap()\n",
       "          (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), dilation=(4, 4), groups=64, bias=False)\n",
       "        )\n",
       "        (bn_prelu): BNPReLU(\n",
       "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act): PReLU(num_parameters=128)\n",
       "        )\n",
       "        (F_glo): FGlo(\n",
       "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc): Sequential(\n",
       "            (0): Linear(in_features=128, out_features=8, bias=True)\n",
       "            (1): ReLU(inplace=True)\n",
       "            (2): Linear(in_features=8, out_features=128, bias=True)\n",
       "            (3): Sigmoid()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (15): ContextGuidedBlock(\n",
       "        (conv1x1): ConvBNPReLU(\n",
       "          (padding): Wrap()\n",
       "          (conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act): PReLU(num_parameters=64)\n",
       "        )\n",
       "        (F_loc): ChannelWiseConv(\n",
       "          (padding): Wrap()\n",
       "          (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), groups=64, bias=False)\n",
       "        )\n",
       "        (F_sur): ChannelWiseDilatedConv(\n",
       "          (padding): Wrap()\n",
       "          (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), dilation=(4, 4), groups=64, bias=False)\n",
       "        )\n",
       "        (bn_prelu): BNPReLU(\n",
       "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act): PReLU(num_parameters=128)\n",
       "        )\n",
       "        (F_glo): FGlo(\n",
       "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc): Sequential(\n",
       "            (0): Linear(in_features=128, out_features=8, bias=True)\n",
       "            (1): ReLU(inplace=True)\n",
       "            (2): Linear(in_features=8, out_features=128, bias=True)\n",
       "            (3): Sigmoid()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (16): ContextGuidedBlock(\n",
       "        (conv1x1): ConvBNPReLU(\n",
       "          (padding): Wrap()\n",
       "          (conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act): PReLU(num_parameters=64)\n",
       "        )\n",
       "        (F_loc): ChannelWiseConv(\n",
       "          (padding): Wrap()\n",
       "          (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), groups=64, bias=False)\n",
       "        )\n",
       "        (F_sur): ChannelWiseDilatedConv(\n",
       "          (padding): Wrap()\n",
       "          (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), dilation=(4, 4), groups=64, bias=False)\n",
       "        )\n",
       "        (bn_prelu): BNPReLU(\n",
       "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act): PReLU(num_parameters=128)\n",
       "        )\n",
       "        (F_glo): FGlo(\n",
       "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc): Sequential(\n",
       "            (0): Linear(in_features=128, out_features=8, bias=True)\n",
       "            (1): ReLU(inplace=True)\n",
       "            (2): Linear(in_features=8, out_features=128, bias=True)\n",
       "            (3): Sigmoid()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (17): ContextGuidedBlock(\n",
       "        (conv1x1): ConvBNPReLU(\n",
       "          (padding): Wrap()\n",
       "          (conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act): PReLU(num_parameters=64)\n",
       "        )\n",
       "        (F_loc): ChannelWiseConv(\n",
       "          (padding): Wrap()\n",
       "          (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), groups=64, bias=False)\n",
       "        )\n",
       "        (F_sur): ChannelWiseDilatedConv(\n",
       "          (padding): Wrap()\n",
       "          (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), dilation=(4, 4), groups=64, bias=False)\n",
       "        )\n",
       "        (bn_prelu): BNPReLU(\n",
       "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act): PReLU(num_parameters=128)\n",
       "        )\n",
       "        (F_glo): FGlo(\n",
       "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc): Sequential(\n",
       "            (0): Linear(in_features=128, out_features=8, bias=True)\n",
       "            (1): ReLU(inplace=True)\n",
       "            (2): Linear(in_features=8, out_features=128, bias=True)\n",
       "            (3): Sigmoid()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (18): ContextGuidedBlock(\n",
       "        (conv1x1): ConvBNPReLU(\n",
       "          (padding): Wrap()\n",
       "          (conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act): PReLU(num_parameters=64)\n",
       "        )\n",
       "        (F_loc): ChannelWiseConv(\n",
       "          (padding): Wrap()\n",
       "          (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), groups=64, bias=False)\n",
       "        )\n",
       "        (F_sur): ChannelWiseDilatedConv(\n",
       "          (padding): Wrap()\n",
       "          (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), dilation=(4, 4), groups=64, bias=False)\n",
       "        )\n",
       "        (bn_prelu): BNPReLU(\n",
       "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act): PReLU(num_parameters=128)\n",
       "        )\n",
       "        (F_glo): FGlo(\n",
       "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc): Sequential(\n",
       "            (0): Linear(in_features=128, out_features=8, bias=True)\n",
       "            (1): ReLU(inplace=True)\n",
       "            (2): Linear(in_features=8, out_features=128, bias=True)\n",
       "            (3): Sigmoid()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (19): ContextGuidedBlock(\n",
       "        (conv1x1): ConvBNPReLU(\n",
       "          (padding): Wrap()\n",
       "          (conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act): PReLU(num_parameters=64)\n",
       "        )\n",
       "        (F_loc): ChannelWiseConv(\n",
       "          (padding): Wrap()\n",
       "          (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), groups=64, bias=False)\n",
       "        )\n",
       "        (F_sur): ChannelWiseDilatedConv(\n",
       "          (padding): Wrap()\n",
       "          (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), dilation=(4, 4), groups=64, bias=False)\n",
       "        )\n",
       "        (bn_prelu): BNPReLU(\n",
       "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act): PReLU(num_parameters=128)\n",
       "        )\n",
       "        (F_glo): FGlo(\n",
       "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc): Sequential(\n",
       "            (0): Linear(in_features=128, out_features=8, bias=True)\n",
       "            (1): ReLU(inplace=True)\n",
       "            (2): Linear(in_features=8, out_features=128, bias=True)\n",
       "            (3): Sigmoid()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (bn_prelu_3): BNPReLU(\n",
       "      (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act): PReLU(num_parameters=256)\n",
       "    )\n",
       "    (classifier): Sequential(\n",
       "      (0): Dropout2d(p=0.1, inplace=False)\n",
       "      (1): Conv(\n",
       "        (padding): Wrap()\n",
       "        (conv): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#gpu\n",
    "#device = torch.device(\"cuda\")\n",
    "net.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "['/glade/scratch/jet/ClimateNet/Climate_data/b.e13.B20TRC5CN.ne120_g16.003.deeplab.2000.poissonfill.nc']\n",
      "Initialized dataset with max length of 2920  time slices\n",
      "Initialized dataset with dataPath= /glade/scratch/jet/ClimateNet/Climate_data/\n",
      "Initialized dataset with file= ['/glade/scratch/jet/ClimateNet/Climate_data/b.e13.B20TRC5CN.ne120_g16.003.deeplab.2000.poissonfill.nc']\n",
      "[54750.125 54750.25  54750.375 ... 55114.75  55114.875 55115.   ]\n"
     ]
    }
   ],
   "source": [
    "import importlib\n",
    "importlib.reload(nc_dataset)\n",
    "#from dataset import cam_dataset as nc_dataset\n",
    "#get data\n",
    "#key names as in nc\n",
    "#var_list = [\"TCWV\",\"U\",\"V\",\"MSL\",\"longitude\",\"latitude\"] #Order matters: #TMQ, U850, V850, PSL, Longitude, Latitude\n",
    "var_list = [\"TMQ\",\"U850\",\"V850\",\"PSL\",\"lon\",\"lat\",\"date\",\"datesec\"] #Order matters: #TMQ, U850, V850, PSL, Longitude, Latitudedataset = nc_dataset.NetcdfDataset(data_dir,variables=var_list[0:4]) #optional: subset=true, condition='regexpconditon'\n",
    "dataset = nc_dataset.NetcdfDataset(data_dir,variables=var_list[0:4]) #optional: subset=true, condition='regexpconditon'\n",
    "print(dataset.ds.variables[\"time\"][:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['TMQ', 'U850', 'V850', 'PSL']\n",
      "lon\n",
      "TMQ\n"
     ]
    }
   ],
   "source": [
    "print(var_list[0:4])\n",
    "print(var_list[4])\n",
    "print(dataset.variables[0])\n",
    "#variables_array = np.array([dataset.variables[var] for var in var_list])\n",
    "x,y=dataset.__getitem__(0)\n",
    "#print(x)\n",
    "#print(y)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 768, 1152)\n",
      "(768, 1152)\n",
      "54750.125\n"
     ]
    }
   ],
   "source": [
    "print(x.shape)\n",
    "print(x[0].shape)\n",
    "print(y)\n",
    "#print(x[0][3][3][0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = DataLoader(dataset, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch #  0  time: tensor(54750.1250)\n",
      "cpu\n",
      "batch #  1  time: tensor(54751.3750)\n",
      "cpu\n",
      "batch #  2  time: tensor(54752.6250)\n",
      "cpu\n",
      "batch #  3  time: tensor(54753.8750)\n",
      "cpu\n",
      "batch #  4  time: tensor(54755.1250)\n",
      "cpu\n",
      "batch #  5  time: tensor(54756.3750)\n",
      "cpu\n",
      "batch #  6  time: tensor(54757.6250)\n",
      "cpu\n",
      "batch #  7  time: tensor(54758.8750)\n",
      "cpu\n",
      "batch #  8  time: tensor(54760.1250)\n",
      "cpu\n",
      "batch #  9  time: tensor(54761.3750)\n",
      "cpu\n",
      "batch #  10  time: tensor(54762.6250)\n",
      "cpu\n",
      "batch #  11  time: tensor(54763.8750)\n",
      "cpu\n",
      "batch #  12  time: tensor(54765.1250)\n",
      "cpu\n",
      "batch #  13  time: tensor(54766.3750)\n",
      "cpu\n",
      "batch #  14  time: tensor(54767.6250)\n",
      "cpu\n",
      "batch #  15  time: tensor(54768.8750)\n",
      "cpu\n",
      "batch #  16  time: tensor(54770.1250)\n",
      "cpu\n",
      "batch #  17  time: tensor(54771.3750)\n",
      "cpu\n",
      "batch #  18  time: tensor(54772.6250)\n",
      "cpu\n",
      "batch #  19  time: tensor(54773.8750)\n",
      "cpu\n",
      "batch #  20  time: tensor(54775.1250)\n",
      "cpu\n",
      "batch #  21  time: tensor(54776.3750)\n",
      "cpu\n",
      "batch #  22  time: tensor(54777.6250)\n",
      "cpu\n",
      "batch #  23  time: tensor(54778.8750)\n",
      "cpu\n",
      "batch #  24  time: tensor(54780.1250)\n",
      "cpu\n",
      "batch #  25  time: tensor(54781.3750)\n",
      "cpu\n",
      "batch #  26  time: tensor(54782.6250)\n",
      "cpu\n",
      "batch #  27  time: tensor(54783.8750)\n",
      "cpu\n",
      "batch #  28  time: tensor(54785.1250)\n",
      "cpu\n",
      "batch #  29  time: tensor(54786.3750)\n",
      "cpu\n",
      "batch #  30  time: tensor(54787.6250)\n",
      "cpu\n",
      "batch #  31  time: tensor(54788.8750)\n",
      "cpu\n",
      "batch #  32  time: tensor(54790.1250)\n",
      "cpu\n",
      "batch #  33  time: tensor(54791.3750)\n",
      "cpu\n",
      "batch #  34  time: tensor(54792.6250)\n",
      "cpu\n",
      "batch #  35  time: tensor(54793.8750)\n",
      "cpu\n",
      "batch #  36  time: tensor(54795.1250)\n",
      "cpu\n",
      "batch #  37  time: tensor(54796.3750)\n",
      "cpu\n",
      "batch #  38  time: tensor(54797.6250)\n",
      "cpu\n",
      "batch #  39  time: tensor(54798.8750)\n",
      "cpu\n",
      "batch #  40  time: tensor(54800.1250)\n",
      "cpu\n",
      "batch #  41  time: tensor(54801.3750)\n",
      "cpu\n",
      "batch #  42  time: tensor(54802.6250)\n",
      "cpu\n",
      "batch #  43  time: tensor(54803.8750)\n",
      "cpu\n",
      "batch #  44  time: tensor(54805.1250)\n",
      "cpu\n",
      "batch #  45  time: tensor(54806.3750)\n",
      "cpu\n",
      "batch #  46  time: tensor(54807.6250)\n",
      "cpu\n",
      "batch #  47  time: tensor(54808.8750)\n",
      "cpu\n",
      "batch #  48  time: tensor(54810.1250)\n",
      "cpu\n",
      "batch #  49  time: tensor(54811.3750)\n",
      "cpu\n",
      "batch #  50  time: tensor(54812.6250)\n",
      "cpu\n",
      "batch #  51  time: tensor(54813.8750)\n",
      "cpu\n",
      "batch #  52  time: tensor(54815.1250)\n",
      "cpu\n",
      "batch #  53  time: tensor(54816.3750)\n",
      "cpu\n",
      "batch #  54  time: tensor(54817.6250)\n",
      "cpu\n",
      "batch #  55  time: tensor(54818.8750)\n",
      "cpu\n",
      "batch #  56  time: tensor(54820.1250)\n",
      "cpu\n",
      "batch #  57  time: tensor(54821.3750)\n",
      "cpu\n",
      "batch #  58  time: tensor(54822.6250)\n",
      "cpu\n",
      "batch #  59  time: tensor(54823.8750)\n",
      "cpu\n",
      "batch #  60  time: tensor(54825.1250)\n",
      "cpu\n",
      "batch #  61  time: tensor(54826.3750)\n",
      "cpu\n",
      "batch #  62  time: tensor(54827.6250)\n",
      "cpu\n",
      "batch #  63  time: tensor(54828.8750)\n",
      "cpu\n",
      "batch #  64  time: tensor(54830.1250)\n",
      "cpu\n",
      "batch #  65  time: tensor(54831.3750)\n",
      "cpu\n",
      "batch #  66  time: tensor(54832.6250)\n",
      "cpu\n",
      "batch #  67  time: tensor(54833.8750)\n",
      "cpu\n",
      "batch #  68  time: tensor(54835.1250)\n",
      "cpu\n",
      "batch #  69  time: tensor(54836.3750)\n",
      "cpu\n",
      "batch #  70  time: tensor(54837.6250)\n",
      "cpu\n",
      "batch #  71  time: tensor(54838.8750)\n",
      "cpu\n",
      "batch #  72  time: tensor(54840.1250)\n",
      "cpu\n",
      "batch #  73  time: tensor(54841.3750)\n",
      "cpu\n",
      "batch #  74  time: tensor(54842.6250)\n",
      "cpu\n",
      "batch #  75  time: tensor(54843.8750)\n",
      "cpu\n",
      "batch #  76  time: tensor(54845.1250)\n",
      "cpu\n",
      "batch #  77  time: tensor(54846.3750)\n",
      "cpu\n",
      "batch #  78  time: tensor(54847.6250)\n",
      "cpu\n",
      "batch #  79  time: tensor(54848.8750)\n",
      "cpu\n",
      "batch #  80  time: tensor(54850.1250)\n",
      "cpu\n",
      "batch #  81  time: tensor(54851.3750)\n",
      "cpu\n",
      "batch #  82  time: tensor(54852.6250)\n",
      "cpu\n",
      "batch #  83  time: tensor(54853.8750)\n",
      "cpu\n",
      "batch #  84  time: tensor(54855.1250)\n",
      "cpu\n",
      "batch #  85  time: tensor(54856.3750)\n",
      "cpu\n",
      "batch #  86  time: tensor(54857.6250)\n",
      "cpu\n",
      "batch #  87  time: tensor(54858.8750)\n",
      "cpu\n",
      "batch #  88  time: tensor(54860.1250)\n",
      "cpu\n",
      "batch #  89  time: tensor(54861.3750)\n",
      "cpu\n",
      "batch #  90  time: tensor(54862.6250)\n",
      "cpu\n",
      "batch #  91  time: tensor(54863.8750)\n",
      "cpu\n",
      "batch #  92  time: tensor(54865.1250)\n",
      "cpu\n",
      "batch #  93  time: tensor(54866.3750)\n",
      "cpu\n",
      "batch #  94  time: tensor(54867.6250)\n",
      "cpu\n",
      "batch #  95  time: tensor(54868.8750)\n",
      "cpu\n",
      "batch #  96  time: tensor(54870.1250)\n",
      "cpu\n",
      "batch #  97  time: tensor(54871.3750)\n",
      "cpu\n",
      "batch #  98  time: tensor(54872.6250)\n",
      "cpu\n",
      "batch #  99  time: tensor(54873.8750)\n",
      "cpu\n",
      "batch #  100  time: tensor(54875.1250)\n",
      "cpu\n",
      "batch #  101  time: tensor(54876.3750)\n",
      "cpu\n",
      "batch #  102  time: tensor(54877.6250)\n",
      "cpu\n",
      "batch #  103  time: tensor(54878.8750)\n",
      "cpu\n",
      "batch #  104  time: tensor(54880.1250)\n",
      "cpu\n",
      "batch #  105  time: tensor(54881.3750)\n",
      "cpu\n",
      "batch #  106  time: tensor(54882.6250)\n",
      "cpu\n",
      "batch #  107  time: tensor(54883.8750)\n",
      "cpu\n",
      "batch #  108  time: tensor(54885.1250)\n",
      "cpu\n",
      "batch #  109  time: tensor(54886.3750)\n",
      "cpu\n",
      "batch #  110  time: tensor(54887.6250)\n",
      "cpu\n",
      "batch #  111  time: tensor(54888.8750)\n",
      "cpu\n",
      "batch #  112  time: tensor(54890.1250)\n",
      "cpu\n",
      "batch #  113  time: tensor(54891.3750)\n",
      "cpu\n",
      "batch #  114  time: tensor(54892.6250)\n",
      "cpu\n",
      "batch #  115  time: tensor(54893.8750)\n",
      "cpu\n",
      "batch #  116  time: tensor(54895.1250)\n",
      "cpu\n",
      "batch #  117  time: tensor(54896.3750)\n",
      "cpu\n",
      "batch #  118  time: tensor(54897.6250)\n",
      "cpu\n",
      "batch #  119  time: tensor(54898.8750)\n",
      "cpu\n",
      "batch #  120  time: tensor(54900.1250)\n",
      "cpu\n",
      "batch #  121  time: tensor(54901.3750)\n",
      "cpu\n",
      "batch #  122  time: tensor(54902.6250)\n",
      "cpu\n",
      "batch #  123  time: tensor(54903.8750)\n",
      "cpu\n",
      "batch #  124  time: tensor(54905.1250)\n",
      "cpu\n",
      "batch #  125  time: tensor(54906.3750)\n",
      "cpu\n",
      "batch #  126  time: tensor(54907.6250)\n",
      "cpu\n",
      "batch #  127  time: tensor(54908.8750)\n",
      "cpu\n",
      "batch #  128  time: tensor(54910.1250)\n",
      "cpu\n",
      "batch #  129  time: tensor(54911.3750)\n",
      "cpu\n",
      "batch #  130  time: tensor(54912.6250)\n",
      "cpu\n",
      "batch #  131  time: tensor(54913.8750)\n",
      "cpu\n",
      "batch #  132  time: tensor(54915.1250)\n",
      "cpu\n",
      "batch #  133  time: tensor(54916.3750)\n",
      "cpu\n",
      "batch #  134  time: tensor(54917.6250)\n",
      "cpu\n",
      "batch #  135  time: tensor(54918.8750)\n",
      "cpu\n",
      "batch #  136  time: tensor(54920.1250)\n",
      "cpu\n",
      "batch #  137  time: tensor(54921.3750)\n",
      "cpu\n",
      "batch #  138  time: tensor(54922.6250)\n",
      "cpu\n",
      "batch #  139  time: tensor(54923.8750)\n",
      "cpu\n",
      "batch #  140  time: tensor(54925.1250)\n",
      "cpu\n",
      "batch #  141  time: tensor(54926.3750)\n",
      "cpu\n",
      "batch #  142  time: tensor(54927.6250)\n",
      "cpu\n",
      "batch #  143  time: tensor(54928.8750)\n",
      "cpu\n",
      "batch #  144  time: tensor(54930.1250)\n",
      "cpu\n",
      "batch #  145  time: tensor(54931.3750)\n",
      "cpu\n",
      "batch #  146  time: tensor(54932.6250)\n",
      "cpu\n",
      "batch #  147  time: tensor(54933.8750)\n",
      "cpu\n",
      "batch #  148  time: tensor(54935.1250)\n",
      "cpu\n",
      "batch #  149  time: tensor(54936.3750)\n",
      "cpu\n",
      "batch #  150  time: tensor(54937.6250)\n",
      "cpu\n",
      "batch #  151  time: tensor(54938.8750)\n",
      "cpu\n",
      "batch #  152  time: tensor(54940.1250)\n",
      "cpu\n",
      "batch #  153  time: tensor(54941.3750)\n",
      "cpu\n",
      "batch #  154  time: tensor(54942.6250)\n",
      "cpu\n",
      "batch #  155  time: tensor(54943.8750)\n",
      "cpu\n",
      "batch #  156  time: tensor(54945.1250)\n",
      "cpu\n",
      "batch #  157  time: tensor(54946.3750)\n",
      "cpu\n",
      "batch #  158  time: tensor(54947.6250)\n",
      "cpu\n",
      "batch #  159  time: tensor(54948.8750)\n",
      "cpu\n",
      "batch #  160  time: tensor(54950.1250)\n",
      "cpu\n",
      "batch #  161  time: tensor(54951.3750)\n",
      "cpu\n",
      "batch #  162  time: tensor(54952.6250)\n",
      "cpu\n",
      "batch #  163  time: tensor(54953.8750)\n",
      "cpu\n",
      "batch #  164  time: tensor(54955.1250)\n",
      "cpu\n",
      "batch #  165  time: tensor(54956.3750)\n",
      "cpu\n",
      "batch #  166  time: tensor(54957.6250)\n",
      "cpu\n",
      "batch #  167  time: tensor(54958.8750)\n",
      "cpu\n",
      "batch #  168  time: tensor(54960.1250)\n",
      "cpu\n",
      "batch #  169  time: tensor(54961.3750)\n",
      "cpu\n",
      "batch #  170  time: tensor(54962.6250)\n",
      "cpu\n",
      "batch #  171  time: tensor(54963.8750)\n",
      "cpu\n",
      "batch #  172  time: tensor(54965.1250)\n",
      "cpu\n",
      "batch #  173  time: tensor(54966.3750)\n",
      "cpu\n",
      "batch #  174  time: tensor(54967.6250)\n",
      "cpu\n",
      "batch #  175  time: tensor(54968.8750)\n",
      "cpu\n",
      "batch #  176  time: tensor(54970.1250)\n",
      "cpu\n",
      "batch #  177  time: tensor(54971.3750)\n",
      "cpu\n",
      "batch #  178  time: tensor(54972.6250)\n",
      "cpu\n",
      "batch #  179  time: tensor(54973.8750)\n",
      "cpu\n",
      "batch #  180  time: tensor(54975.1250)\n",
      "cpu\n",
      "batch #  181  time: tensor(54976.3750)\n",
      "cpu\n",
      "batch #  182  time: tensor(54977.6250)\n",
      "cpu\n",
      "batch #  183  time: tensor(54978.8750)\n",
      "cpu\n",
      "batch #  184  time: tensor(54980.1250)\n",
      "cpu\n",
      "batch #  185  time: tensor(54981.3750)\n",
      "cpu\n",
      "batch #  186  time: tensor(54982.6250)\n",
      "cpu\n",
      "batch #  187  time: tensor(54983.8750)\n",
      "cpu\n",
      "batch #  188  time: tensor(54985.1250)\n",
      "cpu\n",
      "batch #  189  time: tensor(54986.3750)\n",
      "cpu\n",
      "batch #  190  time: tensor(54987.6250)\n",
      "cpu\n",
      "batch #  191  time: tensor(54988.8750)\n",
      "cpu\n",
      "batch #  192  time: tensor(54990.1250)\n",
      "cpu\n",
      "batch #  193  time: tensor(54991.3750)\n",
      "cpu\n",
      "batch #  194  time: tensor(54992.6250)\n",
      "cpu\n",
      "batch #  195  time: tensor(54993.8750)\n",
      "cpu\n",
      "batch #  196  time: tensor(54995.1250)\n",
      "cpu\n",
      "batch #  197  time: tensor(54996.3750)\n",
      "cpu\n",
      "batch #  198  time: tensor(54997.6250)\n",
      "cpu\n",
      "batch #  199  time: tensor(54998.8750)\n",
      "cpu\n",
      "batch #  200  time: tensor(55000.1250)\n",
      "cpu\n",
      "batch #  201  time: tensor(55001.3750)\n",
      "cpu\n",
      "batch #  202  time: tensor(55002.6250)\n",
      "cpu\n",
      "batch #  203  time: tensor(55003.8750)\n",
      "cpu\n",
      "batch #  204  time: tensor(55005.1250)\n",
      "cpu\n",
      "batch #  205  time: tensor(55006.3750)\n",
      "cpu\n",
      "batch #  206  time: tensor(55007.6250)\n",
      "cpu\n",
      "batch #  207  time: tensor(55008.8750)\n",
      "cpu\n",
      "batch #  208  time: tensor(55010.1250)\n",
      "cpu\n",
      "batch #  209  time: tensor(55011.3750)\n",
      "cpu\n",
      "batch #  210  time: tensor(55012.6250)\n",
      "cpu\n",
      "batch #  211  time: tensor(55013.8750)\n",
      "cpu\n",
      "batch #  212  time: tensor(55015.1250)\n",
      "cpu\n",
      "batch #  213  time: tensor(55016.3750)\n",
      "cpu\n",
      "batch #  214  time: tensor(55017.6250)\n",
      "cpu\n",
      "batch #  215  time: tensor(55018.8750)\n",
      "cpu\n",
      "batch #  216  time: tensor(55020.1250)\n",
      "cpu\n",
      "batch #  217  time: tensor(55021.3750)\n",
      "cpu\n",
      "batch #  218  time: tensor(55022.6250)\n",
      "cpu\n",
      "batch #  219  time: tensor(55023.8750)\n",
      "cpu\n",
      "batch #  220  time: tensor(55025.1250)\n",
      "cpu\n",
      "batch #  221  time: tensor(55026.3750)\n",
      "cpu\n",
      "batch #  222  time: tensor(55027.6250)\n",
      "cpu\n",
      "batch #  223  time: tensor(55028.8750)\n",
      "cpu\n",
      "batch #  224  time: tensor(55030.1250)\n",
      "cpu\n",
      "batch #  225  time: tensor(55031.3750)\n",
      "cpu\n",
      "batch #  226  time: tensor(55032.6250)\n",
      "cpu\n",
      "batch #  227  time: tensor(55033.8750)\n",
      "cpu\n",
      "batch #  228  time: tensor(55035.1250)\n",
      "cpu\n",
      "batch #  229  time: tensor(55036.3750)\n",
      "cpu\n",
      "batch #  230  time: tensor(55037.6250)\n",
      "cpu\n",
      "batch #  231  time: tensor(55038.8750)\n",
      "cpu\n",
      "batch #  232  time: tensor(55040.1250)\n",
      "cpu\n",
      "batch #  233  time: tensor(55041.3750)\n",
      "cpu\n",
      "batch #  234  time: tensor(55042.6250)\n",
      "cpu\n",
      "batch #  235  time: tensor(55043.8750)\n",
      "cpu\n",
      "batch #  236  time: tensor(55045.1250)\n",
      "cpu\n",
      "batch #  237  time: tensor(55046.3750)\n",
      "cpu\n",
      "batch #  238  time: tensor(55047.6250)\n",
      "cpu\n",
      "batch #  239  time: tensor(55048.8750)\n",
      "cpu\n",
      "batch #  240  time: tensor(55050.1250)\n",
      "cpu\n",
      "batch #  241  time: tensor(55051.3750)\n",
      "cpu\n",
      "batch #  242  time: tensor(55052.6250)\n",
      "cpu\n",
      "batch #  243  time: tensor(55053.8750)\n",
      "cpu\n",
      "batch #  244  time: tensor(55055.1250)\n",
      "cpu\n",
      "batch #  245  time: tensor(55056.3750)\n",
      "cpu\n",
      "batch #  246  time: tensor(55057.6250)\n",
      "cpu\n",
      "batch #  247  time: tensor(55058.8750)\n",
      "cpu\n",
      "batch #  248  time: tensor(55060.1250)\n",
      "cpu\n",
      "batch #  249  time: tensor(55061.3750)\n",
      "cpu\n",
      "batch #  250  time: tensor(55062.6250)\n",
      "cpu\n",
      "batch #  251  time: tensor(55063.8750)\n",
      "cpu\n",
      "batch #  252  time: tensor(55065.1250)\n",
      "cpu\n",
      "batch #  253  time: tensor(55066.3750)\n",
      "cpu\n",
      "batch #  254  time: tensor(55067.6250)\n",
      "cpu\n",
      "batch #  255  time: tensor(55068.8750)\n",
      "cpu\n",
      "batch #  256  time: tensor(55070.1250)\n",
      "cpu\n",
      "batch #  257  time: tensor(55071.3750)\n",
      "cpu\n",
      "batch #  258  time: tensor(55072.6250)\n",
      "cpu\n",
      "batch #  259  time: tensor(55073.8750)\n",
      "cpu\n",
      "batch #  260  time: tensor(55075.1250)\n",
      "cpu\n",
      "batch #  261  time: tensor(55076.3750)\n",
      "cpu\n",
      "batch #  262  time: tensor(55077.6250)\n",
      "cpu\n",
      "batch #  263  time: tensor(55078.8750)\n",
      "cpu\n",
      "batch #  264  time: tensor(55080.1250)\n",
      "cpu\n",
      "batch #  265  time: tensor(55081.3750)\n",
      "cpu\n",
      "batch #  266  time: tensor(55082.6250)\n",
      "cpu\n",
      "batch #  267  time: tensor(55083.8750)\n",
      "cpu\n",
      "batch #  268  time: tensor(55085.1250)\n",
      "cpu\n",
      "batch #  269  time: tensor(55086.3750)\n",
      "cpu\n",
      "batch #  270  time: tensor(55087.6250)\n",
      "cpu\n",
      "batch #  271  time: tensor(55088.8750)\n",
      "cpu\n",
      "batch #  272  time: tensor(55090.1250)\n",
      "cpu\n",
      "batch #  273  time: tensor(55091.3750)\n",
      "cpu\n",
      "batch #  274  time: tensor(55092.6250)\n",
      "cpu\n",
      "batch #  275  time: tensor(55093.8750)\n",
      "cpu\n",
      "batch #  276  time: tensor(55095.1250)\n",
      "cpu\n",
      "batch #  277  time: tensor(55096.3750)\n",
      "cpu\n",
      "batch #  278  time: tensor(55097.6250)\n",
      "cpu\n",
      "batch #  279  time: tensor(55098.8750)\n",
      "cpu\n",
      "batch #  280  time: tensor(55100.1250)\n",
      "cpu\n",
      "batch #  281  time: tensor(55101.3750)\n",
      "cpu\n",
      "batch #  282  time: tensor(55102.6250)\n",
      "cpu\n",
      "batch #  283  time: tensor(55103.8750)\n",
      "cpu\n",
      "batch #  284  time: tensor(55105.1250)\n",
      "cpu\n",
      "batch #  285  time: tensor(55106.3750)\n",
      "cpu\n",
      "batch #  286  time: tensor(55107.6250)\n",
      "cpu\n",
      "batch #  287  time: tensor(55108.8750)\n",
      "cpu\n",
      "batch #  288  time: tensor(55110.1250)\n",
      "cpu\n",
      "batch #  289  time: tensor(55111.3750)\n",
      "cpu\n",
      "batch #  290  time: tensor(55112.6250)\n",
      "cpu\n",
      "batch #  291  time: tensor(55113.8750)\n",
      "cpu\n"
     ]
    }
   ],
   "source": [
    "for i, (inputs, time) in enumerate(loader):\n",
    "    print(\"batch # \",i,\" time:\",time[0])\n",
    "    #input tensor size should be 1 X 4 X W X H\n",
    "    inputs=inputs.squeeze(0)    \n",
    "    inputs=utils.normalize_0_1_2_7(inputs) #normalize data \n",
    "    print(device)\n",
    "    #push data on GPU and pass forward\n",
    "    inputs = Variable(inputs, requires_grad=True).to(device)\n",
    "    with torch.no_grad():\n",
    "        outputs = net(inputs)\n",
    "    predictions = torch.max(outputs, 1)[1].cpu().numpy();\n",
    "    outfile = str(dataset.case)+str(\"_\")+str(time[0].numpy())+str(\".nc\")\n",
    "    if outfile:\n",
    "        ncout = Dataset(output_dir + outfile ,'w',clobber=True,format='NETCDF4') # using netCDF4 for output format\n",
    "        ncout.createDimension('time',None)\n",
    "        ncout.createDimension('lon',dataset.ds.variables['lon'].shape[0])\n",
    "        ncout.createDimension('lat',dataset.ds.variables['lat'].shape[0])\n",
    "        timevar = ncout.createVariable('time','float32',('time'))\n",
    "        timevar[:] = time\n",
    "        lonvar = ncout.createVariable('lon','float32',('lon'))\n",
    "        lonvar[:] = dataset.ds.variables['lon'][:]\n",
    "        latvar = ncout.createVariable('lat','float32',('lat'))\n",
    "        latvar[:] = dataset.ds.variables['lat'][:]\n",
    "\n",
    "        myvar = ncout.createVariable('output_tag','u1',('time','lat','lon'));\n",
    "        myvar[:] = predictions\n",
    "\n",
    "        #ARs only\n",
    "        #myvar[:] = (predictions==2).astype(int) #0-BG,1-TC,2-AR \n",
    "\n",
    "        #ARTMIP formatting of attributes\n",
    "        timevar.setncatts({'long_name': dataset.ds.variables[\"time\"].long_name,\\\n",
    "                            'units':  dataset.ds.variables[\"time\"].units})\n",
    "        lonvar.setncatts({'long_name': dataset.ds.variables[\"lon\"].long_name,\\\n",
    "                            'units': dataset.ds.variables[\"lon\"].units})\n",
    "        latvar.setncatts({'long_name': dataset.ds.variables[\"lat\"].long_name,\\\n",
    "                            'units': dataset.ds.variables[\"lat\"].units})\n",
    "\n",
    "        myvar.setncatts({'version': u\"CGNet\",\\\n",
    "                        'scheme': u\"ClimateNet_DL_model\",\\\n",
    "                        'description': u\"segmentation tag\"})\n",
    "\n",
    "        ncout.close()       \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
